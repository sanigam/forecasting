{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pmdarima\n",
    "#!pip install fbprophet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load specific forecasting tools\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf # for determining (p,q) orders\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose      # for ETS Plots\n",
    "from pmdarima import auto_arima                              # for determining ARIMA orders\n",
    "\n",
    "# Load specific evaluation tools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "# Ignore harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from fbprophet import Prophet\n",
    "\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LSTM\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creation(input_dim, h1, h2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h1, input_dim=input_dim))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(h2))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return (model)\n",
    "\n",
    "#convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1, offset=0):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-offset):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back+offset])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def nn_pred(train_nn):\n",
    "    model = model_creation(12,6,6)\n",
    "    nn_train = train_nn['y'].values\n",
    "    X, y = create_dataset(nn_train, 12)\n",
    "    model.fit(X, y, epochs=20,shuffle=True,verbose=0)\n",
    "    predictions_nn=[]\n",
    "    trainy = train['y'].values\n",
    "    for i in range(3):\n",
    "        \n",
    "        nn_train = trainy[-12:].reshape(-1,12)\n",
    "        pred = model.predict(nn_train)\n",
    "        predictions_nn.append(pred.flatten()[0])\n",
    "        trainy = np.append(trainy, round(pred.flatten()[0]) )\n",
    "        \n",
    "    predictions_nn = np.array(predictions_nn).round()\n",
    "    return(predictions_nn )\n",
    "\n",
    "def lstm_pred(train, testlen):\n",
    "    n_input = 12\n",
    "    n_features=1\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train)\n",
    "    scaled_train = scaler.transform(train)\n",
    "    #scaled_test = scaler.transform(test)\n",
    "\n",
    "    generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(150, activation='relu', input_shape=(n_input, n_features)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit_generator(generator,epochs=25, verbose = 0)\n",
    "\n",
    "    test_predictions = []\n",
    "    first_eval_batch = scaled_train[-n_input:]\n",
    "    current_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
    "    #print(current_batch)\n",
    "    for i in range(testlen):\n",
    "        #print(current_batch[0])\n",
    "        current_pred = model.predict(current_batch)[0]\n",
    "        test_predictions.append(current_pred) \n",
    "        # From 2nd dim of current batch, drop first value and add latest predition\n",
    "        current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)\n",
    "    true_predictions = np.round(scaler.inverse_transform(test_predictions).flatten())\n",
    "    return true_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('.xlsx', sheet_name = 'FF -MFG Bookings 500')\n",
    "print(df.shape)\n",
    "df['PLID'] = df['PLID'].astype(str)\n",
    "#df[df['PLID'].str.contains('4022058')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby('Fiscal_Year_Month_Number').size()\n",
    "df['ds'] = pd.to_datetime(df['Fiscal_Year_Month_Number'], format=\"%Y%m\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['ds'] = pd.to_datetime(df['Fiscal Year Quarter Number'], format=\"%Y%q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting plids with missing months\n",
    "# for idx, plid in enumerate(df_fc['PLID'].values):   \n",
    "#     df1 = df [ (df['PLID'] ==  plid ) ]\n",
    "#     #print(f'\\n*****{idx} - PLID: {plid} Shape: {df1.shape}*****')\n",
    "#     ds_array = np.arange ( df1['ds'].min(), df1['ds'].max()+ \n",
    "#                       relativedelta(months=1), 1 , dtype='datetime64[M]') \n",
    "#     #print(ds_array)\n",
    "#     df1.sort_values(by = 'ds', inplace=True)\n",
    "#     if len(ds_array) == len(df1): \n",
    "#         df1['ds'] = ds_array\n",
    "#     else:\n",
    "#         #print (f\"'{plid}',\")\n",
    "#         print (plid,len(ds_array),len(df1)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc = pd.read_excel('./PRO/PRO Version - 500 PLIDs .xlsx', sheet_name = 'FantasyForecast PRO')\n",
    "df_fc['PLID'] = df_fc['PLID'].astype(str)\n",
    "print(df_fc.shape)\n",
    "df_fc.rename(columns ={'PLID (DP)': 'PLID'}, inplace = True)\n",
    "display(df_fc.head() )\n",
    "df_fc['model_num'] =  None\n",
    "df_fc['rmse'] = None\n",
    "df_fc['rmse_pct'] = None\n",
    "df_fc['all_mean'] = None\n",
    "df_fc['test_mean'] = None\n",
    "df_fc['train_mean']= None\n",
    "df_fc['latest_6']= None\n",
    "df_fc['predicted']= None\n",
    "df_fc['accuracy']= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc['PLID'] = df_fc['PLID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#df_fc = pd.read_csv('forecast_q2_acc_v1.csv')\n",
    "for idx, plid in enumerate(df_fc['PLID'].values[442:]) :\n",
    "\n",
    "    df1 = df [ (df['PLID'] ==  plid ) ]\n",
    "    print(f'\\n*****{idx} - PLID: {plid} Shape: {df1.shape} {time.asctime()}*****')\n",
    "    \n",
    "    #If rows are less than 4 just put average                       \n",
    "    if df1.shape[0] <= 6:\n",
    "        q_forecast = round(df1['MFG_REV_BKG_QTY'].mean()*3/df1.shape[0])\n",
    "        model_num=99     \n",
    "        cols = ['Q2 FY2021 Forecast (Units)', 'model_num']              \n",
    "        df_fc.loc[df_fc['PLID']==plid, cols] = [q_forecast, model_num] \n",
    "        continue\n",
    "    \n",
    "    df1.sort_values(by = 'ds', inplace=True)\n",
    "\n",
    "    ds_array = np.arange ( df1['ds'].min(), df1['ds'].max()+ \n",
    "                      relativedelta(months=1), 1 , dtype='datetime64[M]') \n",
    "    \n",
    "    #Extraploating missing values in case dates are missing\n",
    "    if len(ds_array) != len(df1):\n",
    "        for dt in ds_array:\n",
    "            if len( df1[df1['ds']==dt]) != 0:\n",
    "                y = df1[df1['ds']==dt]['MFG_REV_BKG_QTY'].values[0]\n",
    "               \n",
    "            else:\n",
    "                df1 = df1.append({'PLID': plid, 'ds':dt,'MFG_REV_BKG_QTY': y }, ignore_index=True)\n",
    "            df1.sort_values(by = 'ds', inplace=True)\n",
    "    \n",
    "    df1 = df1[['ds', 'MFG_REV_BKG_QTY'] ]\n",
    "    df1.columns = ['ds', 'y']\n",
    " \n",
    "    #df1['ds'] = pd.to_datetime(df1['ds'])\n",
    "    train = df1.iloc[:-3]\n",
    "    test = df1.iloc[-3:]\n",
    "    test_mean = round (test['y'].mean())\n",
    "    train_mean = round (train['y'].mean())\n",
    "    all_mean = round (df1['y'].mean())\n",
    "    print(f'All Mean: {all_mean} Train Mean: {train_mean} Test Mean: {test_mean}')\n",
    "    #print(train)\n",
    "    \n",
    "#   Bias = (Forecast-Actual)/Actual\n",
    "#   Accuracy = 1 - Abs(Bias)\n",
    "  \n",
    "    \n",
    "    \n",
    "    # Prohet model\n",
    "    try:\n",
    "        m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality= False)\n",
    "        m.fit(train)\n",
    "        future = m.make_future_dataframe(len(test), freq='MS')\n",
    "        forecast = m.predict(future)\n",
    "\n",
    "        predictions = forecast.iloc[-1*len(test):]['yhat']\n",
    "        error_p_a = round(rmse(predictions,test['y']),2)\n",
    "        bias = (predictions.sum() - test['y'].values.sum())/test['y'].values.sum()\n",
    "        acc_p_a = round( 1- abs(bias ),4)\n",
    "    except:\n",
    "        print ('Prophet Exception')\n",
    "        error_p_a = math.nan\n",
    "        acc_p_a = math.nan\n",
    "        \n",
    "    \n",
    "    # Prohet model Multiplicative\n",
    "    try:\n",
    "        m = Prophet(yearly_seasonality=True , weekly_seasonality=False, daily_seasonality= False, \n",
    "                    seasonality_mode='multiplicative')\n",
    "        m.fit(train)\n",
    "        future = m.make_future_dataframe(len(test), freq='MS')\n",
    "\n",
    "        forecast = m.predict(future)\n",
    "\n",
    "        predictions = forecast.iloc[-1*len(test):]['yhat']\n",
    "        error_p_m = round(rmse(predictions,test['y']),2)\n",
    "        bias = (predictions.sum() - test['y'].values.sum())/test['y'].values.sum()\n",
    "        acc_p_m = round( 1- abs(bias ),4)\n",
    "    except:\n",
    "        print ('Prophet Exception')\n",
    "        error_p_m = math.nan\n",
    "        acc_p_m = math.nan\n",
    "    \n",
    "    print(f'Prophet Error - Add:{error_p_a} Mul:{error_p_m}, Prophet Accuracy - Add:{acc_p_a} Mul:{acc_p_m} ' ) \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "    #ARIMA\n",
    "    df1.set_index('ds', inplace=True)\n",
    "    df1.index.freq = 'MS'\n",
    "    train = df1.iloc[:-3]\n",
    "    test = df1.iloc[-3:]\n",
    "  \n",
    "\n",
    "    \n",
    "    if len(df1)> 39:\n",
    "        s=True\n",
    "        m=12\n",
    "    else:\n",
    "        s = False\n",
    "        m=1\n",
    "    \n",
    "   \n",
    "    #print(df1.info(), df1.index, df1.shape, df1)\n",
    "    try:\n",
    "        model = auto_arima(df1['y'], seasonal=s, m=m, trend='c')\n",
    "        model = SARIMAX( train['y'], order = model.order, seasonal_order= model.seasonal_order)\n",
    "        results = model.fit()\n",
    "        predictions = results.predict ( start = len(train), end=len(train)+len(test)-1, dynamic=False, \n",
    "                                 typ='levels').rename('Prediction')\n",
    "        error_a_c1 = round(rmse(predictions,test['y']),2)\n",
    "        bias = (predictions.sum() - test['y'].values.sum())/test['y'].values.sum()\n",
    "        acc_a_c1 = round( 1- abs(bias ),4)\n",
    "    except:\n",
    "        print ('Exception')\n",
    "        error_a_c1 = math.nan\n",
    "        acc_a_c1 = math.nan\n",
    "        \n",
    "  \n",
    "    try:\n",
    "        model = auto_arima(df1['y'], seasonal=s, m=m, trend='t')\n",
    "        model = SARIMAX( train['y'], order = model.order, seasonal_order= model.seasonal_order)\n",
    "        results = model.fit()\n",
    "        predictions = results.predict ( start = len(train), end=len(train)+len(test)-1, dynamic=False, \n",
    "                                       typ='levels').rename('Prediction')\n",
    "        error_a_t1 = round(rmse(predictions,test['y']),2)\n",
    "        bias = (predictions.sum() - test['y'].values.sum())/test['y'].values.sum()\n",
    "        acc_a_t1 = round( 1- abs(bias ),4)\n",
    "        \n",
    "    except:\n",
    "        print ('Exception')\n",
    "        error_a_t1 = math.nan\n",
    "        acc_a_t1 = math.nan\n",
    "   \n",
    "    try:\n",
    "        model = auto_arima(df1['y'], seasonal=True, m=m, trend='ct')\n",
    "        model = SARIMAX( train['y'], order = model.order, seasonal_order= model.seasonal_order)\n",
    "        results = model.fit()\n",
    "        predictions = results.predict ( start = len(train), end=len(train)+len(test)-1, dynamic=False, \n",
    "                                       typ='levels').rename('Prediction')\n",
    "        error_a_ct1 = round(rmse(predictions,test['y']),2)\n",
    "        bias = (predictions.sum() - test['y'].values.sum())/test['y'].values.sum()\n",
    "        acc_a_ct1 = round( 1- abs(bias ),4)\n",
    "    except:\n",
    "        print ('Exception')\n",
    "        error_a_ct1 = math.nan\n",
    "        acc_a_ct1 = math.nan\n",
    "    \n",
    "    print(f'ARIMA Error - c:{error_a_c1} t:{error_a_t1}  ct:{error_a_ct1}, ARIMA Accuracy - c:{acc_a_c1} t:{acc_a_t1}  ct:{acc_a_ct1}  ' ) \n",
    "  \n",
    "    \n",
    "    #Holt winter\n",
    "#     if len(df1)>= 27:\n",
    "#         m1=12\n",
    "#     else:\n",
    "#         m1=3\n",
    "    \n",
    "#     try:\n",
    "#         fitted_model = ExponentialSmoothing(train['y'],trend='add',seasonal='add',seasonal_periods=m1).fit()\n",
    "#         predictions = fitted_model.forecast(len(test)).rename('HW Forecast')\n",
    "#         error_hwaa = round(rmse(predictions,test['y']),2)\n",
    "#         bias = (predictions.sum() - test['y'].values.sum())/test['y'].values.sum()\n",
    "#         acc_hwaa = round( 1- abs(bias ),4)\n",
    "#     except:\n",
    "#         print ('Exception HWaa')\n",
    "#         error_hwaa = math.nan\n",
    "#         acc_hwaa = math.nan\n",
    "    \n",
    "#     try:\n",
    "#         fitted_model = ExponentialSmoothing(train['y'],trend='add',seasonal='mul',seasonal_periods=m1).fit()\n",
    "#         predictions = fitted_model.forecast(len(test)).rename('HW Forecast')\n",
    "#         error_hwam = round(rmse(predictions,test['y']),2)\n",
    "#         bias = (predictions.sum() - test['y'].values.sum())/test['y'].values.sum()\n",
    "#         acc_hwam = round( 1- abs(bias ),4)\n",
    "#     except:\n",
    "#         print ('Exception in HWam')\n",
    "#         error_hwam = math.nan\n",
    "#         acc_hwam = math.nan\n",
    "    \n",
    "#     try:\n",
    "#         fitted_model = ExponentialSmoothing(train['y'],trend='mul',seasonal='add',seasonal_periods=m1).fit()\n",
    "#         predictions = fitted_model.forecast(len(test)).rename('HW Forecast')\n",
    "#         error_hwma = round(rmse(predictions,test['y']),2)\n",
    "#         bias = (predictions.sum() - test['y'].values.sum())/test['y'].values.sum()\n",
    "#         acc_hwma = round( 1- abs(bias ),4)\n",
    "#     except:\n",
    "#         print ('Exception in HWma')\n",
    "#         error_hwma = math.nan\n",
    "#         acc_hwma = math.nan\n",
    "    \n",
    "#     try:\n",
    "#         fitted_model = ExponentialSmoothing(train['y'],trend='mul',seasonal='mul',seasonal_periods=m1).fit()\n",
    "#         predictions = fitted_model.forecast(len(test)).rename('HW Forecast')\n",
    "#         error_hwmm = round(rmse(predictions,test['y']),2)\n",
    "#         bias = (predictions.sum() - test['y'].values.sum())/test['y'].values.sum()\n",
    "#         acc_hwmm = round( 1- abs(bias ),4)\n",
    "#     except:\n",
    "#         print ('Exception HWmm')\n",
    "#         error_hwmm = math.nan\n",
    "#         acc_hwmm = math.nan\n",
    "        \n",
    "#     print(f'HW Error - aa:{error_hwaa} am:{error_hwam} ma:{error_hwma} mm:{error_hwmm}, HW Accuracy - aa:{acc_hwaa} am:{acc_hwam} ma:{acc_hwma} mm:{acc_hwmm}  ' ) \n",
    "\n",
    "\n",
    "    #Neural Network\n",
    "#     try:\n",
    "#         predictions = lstm_pred(train, len(test) )\n",
    "#         error_nn = round( np.sqrt(mean_squared_error(predictions,test['y'].values)), 2)\n",
    "#         bias = (predictions.sum() - test['y'].values.sum())/test['y'].values.sum()\n",
    "#         acc_nn = round( 1- abs(bias ),4)\n",
    "        \n",
    "#         error_nn = math.inf\n",
    "#         acc_nn = - math.inf\n",
    "#     except:\n",
    "#         print ('Exception in lstm model')\n",
    "#         error_nn = math.nan\n",
    "#         acc_nn =  math.nan\n",
    "#     print(f'LSTM Error: {error_nn}, LSTM Accuracy: {acc_nn}')\n",
    "\n",
    "    error_hwaa = math.inf\n",
    "    acc_hwaa = - math.inf\n",
    "    error_hwam = math.inf\n",
    "    acc_hwam = - math.inf\n",
    "    error_hwma = math.inf\n",
    "    acc_hwma = - math.inf\n",
    "    error_hwmm = math.inf\n",
    "    acc_hwmm = - math.inf    \n",
    "    error_nn = math.inf\n",
    "    acc_nn = - math.inf\n",
    "\n",
    "\n",
    "    error_list = [error_p_a, error_p_m,error_a_c1, error_a_t1, error_a_ct1 , error_hwaa, error_hwam, \n",
    "                  error_hwma, error_hwmm, error_nn]\n",
    "    error_list = np.nan_to_num(error_list, copy=True, nan=math.inf)\n",
    "    \n",
    "    acc_list = [acc_p_a, acc_p_m,acc_a_c1, acc_a_t1, acc_a_ct1 , acc_hwaa, acc_hwam, \n",
    "                  acc_hwma, acc_hwmm, acc_nn]\n",
    "    acc_list = np.nan_to_num(acc_list, copy=True, nan= -math.inf)\n",
    "    \n",
    "    model_num = np.argmin(error_list)\n",
    "    #model_num = np.argmax(acc_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(model_num)\n",
    "\n",
    "    rmse_final = error_list[model_num]\n",
    "    rmse_pct = round(error_list[model_num]*100/test_mean,2)\n",
    "    acc_final = acc_list[model_num]\n",
    "    latest_6 = df1['y'].values[-6:]\n",
    "    if model_num == 0:\n",
    "        if df1.shape[1] == 1:\n",
    "            df1.reset_index(inplace=True)\n",
    "        m = Prophet()\n",
    "        m.fit(df1)\n",
    "        future = m.make_future_dataframe(3, freq='MS')\n",
    "        forecast = m.predict(future)\n",
    "        predictions = forecast.iloc[-3:]['yhat'].values\n",
    "    elif model_num == 1:\n",
    "        if df1.shape[1] == 1:\n",
    "            df1.reset_index(inplace=True)\n",
    "        m = Prophet(seasonality_mode='multiplicative')\n",
    "        m.fit(df1)\n",
    "        future = m.make_future_dataframe(3, freq='MS')\n",
    "        forecast = m.predict(future)\n",
    "        predictions = forecast.iloc[-3:]['yhat'].values\n",
    "    elif model_num == 2:\n",
    "        model = auto_arima(df1['y'], seasonal=s, m=m, trend='c')\n",
    "        model = SARIMAX( df1['y'], order = model.order, seasonal_order= model.seasonal_order)\n",
    "        results = model.fit()\n",
    "        predictions = results.predict ( start = len(df1), end=len(df1)+2, dynamic=False, \n",
    "                                   typ='levels').values\n",
    "    elif model_num == 3:\n",
    "        model = auto_arima(df1['y'], seasonal=s, m=m, trend='t')\n",
    "        model = SARIMAX( df1['y'], order = model.order, seasonal_order= model.seasonal_order)\n",
    "        results = model.fit()\n",
    "        predictions = results.predict ( start = len(df1), end=len(df1)+2, dynamic=False, \n",
    "                                   typ='levels').values\n",
    "    elif model_num == 4:\n",
    "        model = auto_arima(df1['y'], seasonal=s, m=m, trend='ct')\n",
    "        model = SARIMAX( df1['y'], order = model.order, seasonal_order= model.seasonal_order)\n",
    "        results = model.fit()\n",
    "        predictions = results.predict ( start = len(df1), end=len(df1)+2, dynamic=False, \n",
    "                                   typ='levels').values\n",
    "    elif model_num == 5:\n",
    "        fitted_model = ExponentialSmoothing(df1['y'],trend='add',seasonal='add',seasonal_periods=m1).fit()\n",
    "        predictions = fitted_model.forecast(3).values\n",
    "    elif model_num == 6:\n",
    "        fitted_model = ExponentialSmoothing(df1['y'],trend='add',seasonal='mul',seasonal_periods=m1).fit()\n",
    "        predictions = fitted_model.forecast(3).values\n",
    "    elif model_num == 7:\n",
    "        fitted_model = ExponentialSmoothing(df1['y'],trend='mul',seasonal='add',seasonal_periods=m1).fit()\n",
    "        predictions = fitted_model.forecast(3).values\n",
    "    elif model_num == 8:\n",
    "        fitted_model = ExponentialSmoothing(df1['y'],trend='mul',seasonal='mul',seasonal_periods=m1).fit()\n",
    "        predictions = fitted_model.forecast(3).values\n",
    "    elif model_num == 9:\n",
    "        predictions = lstm_pred(df1,3)\n",
    "    else:\n",
    "        print('There is an issue')\n",
    "    \n",
    "    print (f'Model Num:{model_num} RMSE={rmse_final} RMSE%={rmse_pct} Accuracy={acc_final} Latest 6={latest_6} Predictions={predictions.round()}')\n",
    "    \n",
    "#     plt.figure(figsize=(10,1))\n",
    "#     plt.plot(range(9), np.concatenate([latest_6,predictions]), marker='o' )\n",
    "    \n",
    "    q_forecast = round(predictions.sum())\n",
    "    #print(plid, q_forecast, rmse_final,rmse_pct, test_mean,train_mean, model_num)\n",
    "    \n",
    "    cols = ['Q2 FY2021 Forecast (Units)', 'model_num', 'rmse', 'rmse_pct', 'accuracy','all_mean','test_mean', \\\n",
    "            'train_mean', 'latest_6', 'predicted' ]\n",
    "    \n",
    "    df_fc.loc[df_fc['PLID']==plid, cols] = \\\n",
    "         [q_forecast, model_num, rmse_final,rmse_pct,acc_final, all_mean, test_mean,train_mean, str(latest_6),str(predictions.round()) ] \n",
    "    \n",
    "    df_fc.to_csv('forecast_q2_acc_v1.csv', index=False)\n",
    "#     print(df1.shape, predictions.shape)   \n",
    "#     title='Booking Forecast Model #' + str(model_num) \n",
    "#     ylabel='Monthly Bookings'\n",
    "#     xlabel=''\n",
    "#     ax = df1.plot(legend=True,figsize=(12,4),title=title)\n",
    "#     predictions.plot(legend=True)\n",
    "#     ax.autoscale(axis='x',tight=True)\n",
    "#     ax.set(xlabel=xlabel, ylabel=ylabel);\n",
    "#     time.sleep(0.1)\n",
    "#     plt.pause(0.0001)  \n",
    "        \n",
    "    \n",
    "\n",
    "              \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['PLID']=='87977']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fc.to_csv('forecast_q2_acc_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc.groupby('model_num').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fc = pd.read_csv('forecast_q2_acc_v1.csv')\n",
    "df_fc.groupby('model_num').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc[df_fc['model_num'].notnull()].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_fc[df_fc['model_num'].notnull()].shape )\n",
    "df_fc[df_fc['model_num'].notnull()].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fc[df_fc['model_num']== 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =  pd.read_csv('forecast_q2_acc_v1.csv')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Forecast'] = df1['Q2 FY2021 Forecast (Units)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[ (df1['accuracy'] < .5) | (df1['accuracy'] == -math.inf)  , 'Forecast'] = df1['test_mean']*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df1['accuracy'] < .5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge ( df , df1[df1.model_num == 99]['PLID'], on ='PLID', how ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sort_values(by = ['PLID','ds' ], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.groupby(\"PLID\")[\"MFG_REV_BKG_QTY\"].apply(lambda x: round(x.iloc[-3:].sum()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.rename({'MFG_REV_BKG_QTY': 'Forecast1'}, axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.merge(df1, df3, on = 'PLID', how='left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df1.model_num == 99, 'Forecast'] = df1['Forecast1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df1.model_num == 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('forecast_q2_acc_v1_modified.csv', index = 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage(deep=True).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel ('forecast_q2_acc_v1_modified_subm.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel ('Q2FY21 - 3 Cycle Forecast (STAT,CDO,BASE)_avg.xlsx')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['PLID (DP)', 'Avg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.rename({'PLID (DP)': 'PLID'}, axis = 1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Avg'] = df1['Avg'].apply(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df1, on ='PLID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Forecast_new'] = df['Forecast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['accuracy']<= .7) | (df['model_num']==99), 'Forecast_new'] = df['Avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Forecast_new'] = df['Forecast_new'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('q2_new_forecast_subm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
